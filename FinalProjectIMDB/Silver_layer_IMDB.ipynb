{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a595f3a-eede-46e4-a5b0-a484aa497757",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import (\n",
    "    col, when, trim, split, year, current_timestamp,\n",
    "    lit, regexp_replace, regexp_extract\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5ad29d8-062c-44de-a4c3-c7a04a71fb8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================\n",
    "# SILVER - NAME BASICS\n",
    "# ============================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"silver_name_basics\",\n",
    "    comment=\"Cleaned name.basics data (persons) from IMDb\",\n",
    "    table_properties={\n",
    "        \"delta.columnMapping.mode\": \"name\",\n",
    "        \"quality\": \"silver\"\n",
    "    }\n",
    ")\n",
    "def silver_name_basics():\n",
    "    df = dlt.read(\"raw_name_basics\")\n",
    "\n",
    "    # Current year for simple range checks\n",
    "    current_year = year(current_timestamp())\n",
    "\n",
    "    # Helper to turn '\\N' into null\n",
    "    def null_if_N(cname):\n",
    "        return when((col(cname) == \"\\\\N\") | (col(cname) == \"\"), None).otherwise(col(cname))\n",
    "\n",
    "    # --- Clean base columns ---\n",
    "    df_clean = (\n",
    "        df\n",
    "        # nconst: trim and keep only valid PKs later\n",
    "        .withColumn(\"nconst\", trim(col(\"nconst\")))\n",
    "        .withColumn(\"primary_name\", trim(col(\"primaryName\")))\n",
    "\n",
    "        # Replace '\\N' with null for year columns\n",
    "        .withColumn(\"birth_year_raw\", null_if_N(\"birthYear\").cast(\"int\"))\n",
    "        .withColumn(\"death_year_raw\", null_if_N(\"deathYear\").cast(\"int\"))\n",
    "\n",
    "        # Profession / known-for raw strings (null instead of '\\N')\n",
    "        .withColumn(\"primary_profession_raw\", trim(null_if_N(\"primaryProfession\")))\n",
    "        .withColumn(\"known_for_titles_raw\", trim(null_if_N(\"knownForTitles\")))\n",
    "    )\n",
    "\n",
    "    # --- Validate year ranges ---\n",
    "    df_years = (\n",
    "        df_clean\n",
    "        # Birth year: keep only sensible values\n",
    "        .withColumn(\n",
    "            \"birth_year\",\n",
    "            when(\n",
    "                (col(\"birth_year_raw\") >= lit(1850)) &\n",
    "                (col(\"birth_year_raw\") <= current_year + lit(1)),\n",
    "                col(\"birth_year_raw\")\n",
    "            ).otherwise(None)\n",
    "        )\n",
    "        # Death year: range check\n",
    "        .withColumn(\n",
    "            \"death_year_tmp\",\n",
    "            when(\n",
    "                (col(\"death_year_raw\") >= lit(1850)) &\n",
    "                (col(\"death_year_raw\") <= current_year + lit(1)),\n",
    "                col(\"death_year_raw\")\n",
    "            ).otherwise(None)\n",
    "        )\n",
    "        # Death year must not be before birth year\n",
    "        .withColumn(\n",
    "            \"death_year\",\n",
    "            when(\n",
    "                col(\"death_year_tmp\").isNotNull()\n",
    "                & col(\"birth_year\").isNotNull()\n",
    "                & (col(\"death_year_tmp\") < col(\"birth_year\")),\n",
    "                None\n",
    "            ).otherwise(col(\"death_year_tmp\"))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # --- Parse arrays ---\n",
    "    df_arrays = (\n",
    "        df_years\n",
    "        # Profession array\n",
    "        .withColumn(\n",
    "            \"primary_profession_array\",\n",
    "            when(\n",
    "                col(\"primary_profession_raw\").isNotNull(),\n",
    "                split(col(\"primary_profession_raw\"), r\"\\s*,\\s*\")\n",
    "            ).otherwise(None)\n",
    "        )\n",
    "        # Known-for titles array\n",
    "        .withColumn(\n",
    "            \"known_for_titles_array\",\n",
    "            when(\n",
    "                col(\"known_for_titles_raw\").isNotNull(),\n",
    "                split(col(\"known_for_titles_raw\"), r\"\\s*,\\s*\")\n",
    "            ).otherwise(None)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # --- Filter invalid PKs (drop rows with bad nconst) ---\n",
    "    df_filtered = df_arrays.filter(\n",
    "        (col(\"nconst\").isNotNull()) &\n",
    "        (col(\"nconst\") != \"\") &\n",
    "        (col(\"nconst\") != \"\\\\N\")\n",
    "    )\n",
    "\n",
    "    # --- Final column selection ---\n",
    "    return df_filtered.select(\n",
    "        col(\"nconst\").alias(\"name_id\"),\n",
    "        \"primary_name\",\n",
    "        \"birth_year\",\n",
    "        \"death_year\",\n",
    "        \"primary_profession_raw\",\n",
    "        \"primary_profession_array\",\n",
    "        \"known_for_titles_raw\",\n",
    "        \"known_for_titles_array\",\n",
    "      \n",
    "        \"load_dt\",\n",
    "        \"source_file_name\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2546c1ac-0786-43c3-9099-7b7409b15250",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Helper to normalize '\\N' to null\n",
    "def null_if_N(cname):\n",
    "    return when((col(cname) == \"\\\\N\") | (col(cname) == \"\"), None).otherwise(col(cname))\n",
    "\n",
    "# ============================\n",
    "# SILVER - TITLE BASICS\n",
    "# ============================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"silver_title_basics\",\n",
    "    comment=\"Cleaned title.basics data for building dim_title\",\n",
    "    table_properties={\n",
    "        \"delta.columnMapping.mode\": \"name\",\n",
    "        \"quality\": \"silver\"\n",
    "    }\n",
    ")\n",
    "def silver_title_basics():\n",
    "    df = dlt.read(\"raw_title_basics\")\n",
    "\n",
    "    current_year = year(current_timestamp())\n",
    "\n",
    "    df_clean = (\n",
    "        df\n",
    "        # Rename & trim\n",
    "        .withColumn(\"tconst\", trim(col(\"tconst\")))\n",
    "        .withColumn(\"title_type\", trim(col(\"titleType\")))\n",
    "        .withColumn(\"primary_title\", trim(col(\"primaryTitle\")))\n",
    "        .withColumn(\"original_title\", trim(col(\"originalTitle\")))\n",
    "\n",
    "        # isAdult: '\\N' → null, then cast to boolean\n",
    "        .withColumn(\"is_adult_int\", null_if_N(\"isAdult\").cast(\"int\"))\n",
    "        .withColumn(\n",
    "            \"is_adult\",\n",
    "            when(col(\"is_adult_int\") == 1, lit(True))\n",
    "            .when(col(\"is_adult_int\") == 0, lit(False))\n",
    "            .otherwise(None)\n",
    "        )\n",
    "\n",
    "        # Years: '\\N' → null, cast to int, basic range sanity\n",
    "        .withColumn(\"start_year_raw\", null_if_N(\"startYear\").cast(\"int\"))\n",
    "        .withColumn(\"end_year_raw\", null_if_N(\"endYear\").cast(\"int\"))\n",
    "        .withColumn(\n",
    "            \"start_year\",\n",
    "            when(\n",
    "                (col(\"start_year_raw\") >= lit(1850)) &\n",
    "                (col(\"start_year_raw\") <= current_year + lit(1)),\n",
    "                col(\"start_year_raw\")\n",
    "            ).otherwise(None)\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"end_year\",\n",
    "            when(\n",
    "                (col(\"end_year_raw\") >= lit(1850)) &\n",
    "                (col(\"end_year_raw\") <= current_year + lit(10)),\n",
    "                col(\"end_year_raw\")\n",
    "            ).otherwise(None)\n",
    "        )\n",
    "\n",
    "        # runtimeMinutes: '\\N' → null, cast to int, non-negative\n",
    "        .withColumn(\"runtime_minutes_raw\", null_if_N(\"runtimeMinutes\").cast(\"int\"))\n",
    "        .withColumn(\n",
    "            \"runtime_minutes\",\n",
    "            when(col(\"runtime_minutes_raw\") >= 0, col(\"runtime_minutes_raw\")).otherwise(None)\n",
    "        )\n",
    "\n",
    "        # genres: '\\N' → null, then split to array\n",
    "        .withColumn(\"genres_str\", null_if_N(\"genres\"))\n",
    "        .withColumn(\n",
    "            \"genres\",\n",
    "            when(col(\"genres_str\").isNotNull(),\n",
    "                 split(col(\"genres_str\"), r\"\\s*,\\s*\")\n",
    "            ).otherwise(None)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Drop any rows with missing tconst (should be none, but defensive)\n",
    "    df_filtered = df_clean.filter(\n",
    "        (col(\"tconst\").isNotNull()) &\n",
    "        (col(\"tconst\") != \"\") &\n",
    "        (col(\"tconst\") != \"\\\\N\")\n",
    "    )\n",
    "\n",
    "    # Final minimal projection\n",
    "    return df_filtered.select(\n",
    "        col(\"tconst\").alias(\"title_id\"),\n",
    "        \"title_type\",\n",
    "        \"primary_title\",\n",
    "        \"original_title\",\n",
    "        \"is_adult\",\n",
    "        \"start_year\",\n",
    "        \"end_year\",\n",
    "        \"runtime_minutes\",\n",
    "        \"genres\",\n",
    "        \"load_dt\",\n",
    "        \"source_file_name\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0ff6663-a1a9-420a-8384-08321309a28d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================\n",
    "# SILVER - TITLE EPISODE\n",
    "# ============================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"silver_title_episode\",\n",
    "    comment=\"Cleaned title.episode data for enriching dim_title with series/episode info\",\n",
    "    table_properties={\n",
    "        \"delta.columnMapping.mode\": \"name\",\n",
    "        \"quality\": \"silver\"\n",
    "    }\n",
    ")\n",
    "def silver_title_episode():\n",
    "    df = dlt.read(\"raw_title_episode\")\n",
    "\n",
    "    df_clean = (\n",
    "        df\n",
    "        .withColumn(\"tconst\", trim(col(\"tconst\")))\n",
    "        .withColumn(\"parent_tconst\", trim(null_if_N(\"parentTconst\")))\n",
    "        .withColumn(\n",
    "            \"season_number\",\n",
    "            null_if_N(\"seasonNumber\").cast(\"int\")\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"episode_number\",\n",
    "            null_if_N(\"episodeNumber\").cast(\"int\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # tconst is mandatory; if somehow missing, drop those rows\n",
    "    df_filtered = df_clean.filter(\n",
    "        (col(\"tconst\").isNotNull()) &\n",
    "        (col(\"tconst\") != \"\") &\n",
    "        (col(\"tconst\") != \"\\\\N\")\n",
    "    )\n",
    "\n",
    "    return df_filtered.select(\n",
    "        col(\"tconst\").alias(\"title_id\"),\n",
    "        col(\"parent_tconst\").alias(\"parent_title_id\"),\n",
    "        \"season_number\",\n",
    "        \"episode_number\",\n",
    "        \"load_dt\",\n",
    "        \"source_file_name\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a5fcca1-0a95-47c8-a129-eba2571bc578",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================\n",
    "# SILVER - TITLE AKAS\n",
    "# ============================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"silver_title_akas\",\n",
    "    comment=\"Cleaned title.akas data for regions and languages per title\",\n",
    "    table_properties={\n",
    "        \"delta.columnMapping.mode\": \"name\",\n",
    "        \"quality\": \"silver\"\n",
    "    }\n",
    ")\n",
    "def silver_title_akas():\n",
    "    df = dlt.read(\"raw_title_akas\")\n",
    "\n",
    "    df_clean = (\n",
    "        df\n",
    "        # rename + trim\n",
    "        .withColumn(\"tconst\", trim(col(\"titleId\")))\n",
    "        .withColumn(\"aka_title\", trim(col(\"title\")))\n",
    "        .withColumn(\"ordering_int\", null_if_N(\"ordering\").cast(\"int\"))\n",
    "\n",
    "        # region & language: '\\N' -> null\n",
    "        .withColumn(\"region\", trim(null_if_N(\"region\")))\n",
    "        .withColumn(\"language\", trim(null_if_N(\"language\")))\n",
    "\n",
    "        # isOriginalTitle: '\\N' or null allowed -> boolean\n",
    "        .withColumn(\"is_original_title_int\", null_if_N(\"isOriginalTitle\").cast(\"int\"))\n",
    "        .withColumn(\n",
    "            \"is_original_title\",\n",
    "            when(col(\"is_original_title_int\") == 1, lit(True))\n",
    "            .when(col(\"is_original_title_int\") == 0, lit(False))\n",
    "            .otherwise(None)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Drop rows with missing tconst defensively\n",
    "    df_filtered = df_clean.filter(\n",
    "        (col(\"tconst\").isNotNull()) &\n",
    "        (col(\"tconst\") != \"\") &\n",
    "        (col(\"tconst\") != \"\\\\N\")\n",
    "    )\n",
    "\n",
    "    return df_filtered.select(\n",
    "        col(\"tconst\").alias(\"title_id\"),\n",
    "        col(\"ordering_int\").alias(\"ordering\"),\n",
    "        \"aka_title\",\n",
    "        \"region\",\n",
    "        \"language\",\n",
    "        \"is_original_title\",\n",
    "        \"load_dt\",\n",
    "        \"source_file_name\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a4fb82e-55e3-4b40-aaa6-b9a0aae7bc35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================\n",
    "# SILVER - TITLE PRINCIPALS\n",
    "# ============================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"silver_title_principals\",\n",
    "    comment=\"Cleaned title.principals data for cast/crew, jobs, and characters per title\",\n",
    "    table_properties={\n",
    "        \"delta.columnMapping.mode\": \"name\",\n",
    "        \"quality\": \"silver\"\n",
    "    }\n",
    ")\n",
    "def silver_title_principals():\n",
    "    df = dlt.read(\"raw_title_principals\")\n",
    "\n",
    "    df_clean = (\n",
    "        df\n",
    "        # trim & rename\n",
    "        .withColumn(\"tconst\", trim(col(\"tconst\")))\n",
    "        .withColumn(\"nconst\", trim(col(\"nconst\")))\n",
    "        .withColumn(\"ordering_int\", null_if_N(\"ordering\").cast(\"int\"))\n",
    "        .withColumn(\"category\", trim(null_if_N(\"category\")))\n",
    "        .withColumn(\"job\", trim(null_if_N(\"job\")))\n",
    "\n",
    "        # characters: '\\N' -> null, then strip [ ] and quotes\n",
    "        .withColumn(\"characters_raw\", null_if_N(\"characters\"))\n",
    "        .withColumn(\n",
    "            \"characters_clean\",\n",
    "            when(\n",
    "                col(\"characters_raw\").isNotNull(),\n",
    "                regexp_replace(col(\"characters_raw\"), r'[\\[\\]\\\"]', \"\")\n",
    "            ).otherwise(None)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Drop rows missing tconst or nconst (invalid relationships)\n",
    "    df_filtered = df_clean.filter(\n",
    "        (col(\"tconst\").isNotNull()) & (col(\"tconst\") != \"\") & (col(\"tconst\") != \"\\\\N\") &\n",
    "        (col(\"nconst\").isNotNull()) & (col(\"nconst\") != \"\") & (col(\"nconst\") != \"\\\\N\")\n",
    "    )\n",
    "\n",
    "    return df_filtered.select(\n",
    "        col(\"tconst\").alias(\"title_id\"),\n",
    "        col(\"nconst\").alias(\"name_id\"),\n",
    "        col(\"ordering_int\").alias(\"ordering\"),\n",
    "        \"category\",\n",
    "        \"job\",\n",
    "        col(\"characters_clean\").alias(\"characters\"),\n",
    "        \"load_dt\",\n",
    "        \"source_file_name\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9c97261-d7b5-4542-aac4-3c197069f57b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================\n",
    "# SILVER - TITLE CREW\n",
    "# ============================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"silver_title_crew\",\n",
    "    comment=\"Cleaned title.crew data for directors and writers per title\",\n",
    "    table_properties={\n",
    "        \"delta.columnMapping.mode\": \"name\",\n",
    "        \"quality\": \"silver\"\n",
    "    }\n",
    ")\n",
    "def silver_title_crew():\n",
    "    df = dlt.read(\"raw_title_crew\")\n",
    "\n",
    "    df_clean = (\n",
    "        df\n",
    "        # tconst\n",
    "        .withColumn(\"tconst\", trim(col(\"tconst\")))\n",
    "\n",
    "        # raw strings with '\\N' -> null\n",
    "        .withColumn(\"directors_raw\", trim(null_if_N(\"directors\")))\n",
    "        .withColumn(\"writers_raw\", trim(null_if_N(\"writers\")))\n",
    "\n",
    "        # arrays of nconsts (no explode in Silver)\n",
    "        .withColumn(\n",
    "            \"directors_array\",\n",
    "            when(\n",
    "                col(\"directors_raw\").isNotNull(),\n",
    "                split(col(\"directors_raw\"), r\"\\s*,\\s*\")\n",
    "            ).otherwise(None)\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"writers_array\",\n",
    "            when(\n",
    "                col(\"writers_raw\").isNotNull(),\n",
    "                split(col(\"writers_raw\"), r\"\\s*,\\s*\")\n",
    "            ).otherwise(None)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # drop rows with missing tconst (defensive)\n",
    "    df_filtered = df_clean.filter(\n",
    "        (col(\"tconst\").isNotNull()) &\n",
    "        (col(\"tconst\") != \"\") &\n",
    "        (col(\"tconst\") != \"\\\\N\")\n",
    "    )\n",
    "\n",
    "    return df_filtered.select(\n",
    "        col(\"tconst\").alias(\"title_id\"),\n",
    "        \"directors_raw\",\n",
    "        \"directors_array\",\n",
    "        \"writers_raw\",\n",
    "        \"writers_array\",\n",
    "        \"load_dt\",\n",
    "        \"source_file_name\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95715ef3-9cf4-4b6e-b4dd-7221fc096cd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================\n",
    "# SILVER - TITLE RAITINGS\n",
    "# ============================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"silver_title_ratings\",\n",
    "    comment=\"Cleaned title.ratings data for fact_title_ratings\",\n",
    "    table_properties={\n",
    "        \"delta.columnMapping.mode\": \"name\",\n",
    "        \"quality\": \"silver\"\n",
    "    }\n",
    ")\n",
    "def silver_title_ratings():\n",
    "    df = dlt.read(\"raw_title_ratings\")\n",
    "\n",
    "    df_clean = (\n",
    "        df\n",
    "        .withColumn(\"tconst\", trim(col(\"tconst\")))\n",
    "        .withColumn(\"average_rating\",\n",
    "                    null_if_N(\"averageRating\").cast(\"double\"))\n",
    "        .withColumn(\"num_votes\",\n",
    "                    null_if_N(\"numVotes\").cast(\"int\"))\n",
    "    )\n",
    "\n",
    "    df_filtered = df_clean.filter(\n",
    "        (col(\"tconst\").isNotNull()) &\n",
    "        (col(\"tconst\") != \"\") &\n",
    "        (col(\"tconst\") != \"\\\\N\")\n",
    "    )\n",
    "\n",
    "    return df_filtered.select(\n",
    "        col(\"tconst\").alias(\"title_id\"),\n",
    "        \"average_rating\",\n",
    "        \"num_votes\",\n",
    "        \"load_dt\",\n",
    "        \"source_file_name\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Silver_layer_IMDB",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
